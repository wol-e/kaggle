{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"data/source/sales_train.csv\")\n",
    "sales[\"date\"] = sales[\"date\"].apply(lambda x: datetime.strptime(x, \"%d.%m.%Y\"))\n",
    "display(sales.head(5))\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"data/source/items.csv\")\n",
    "cats = pd.read_csv(\"data/source/item_categories.csv\")\n",
    "\n",
    "items = items.join(cats.set_index(\"item_category_id\"), how=\"left\", on=\"item_category_id\")\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = pd.read_csv(\"data/source/shops.csv\")\n",
    "\n",
    "shops.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/source/test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we merge all shop_id, item_id combinations from train and test set\n",
    "shop_item = sales[[\"shop_id\", \"item_id\"]].drop_duplicates().join(\n",
    "    test.set_index([\"shop_id\", \"item_id\"]), on=[\"shop_id\", \"item_id\"], how=\"outer\"\n",
    ")[[\"shop_id\", \"item_id\"]].reset_index(drop=True)\n",
    "\n",
    "# add item and shop metadata\n",
    "shop_item = shop_item.join(items.set_index(\"item_id\"), how=\"left\", on=\"item_id\")\n",
    "shop_item = shop_item.join(shops.set_index(\"shop_id\"), on=\"shop_id\", how=\"left\")\n",
    "\n",
    "shop_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_item = shop_item.merge(pd.DataFrame({\"date_block_num\": range(34)}), how=\"cross\")\n",
    "\n",
    "#reduce memory usage\n",
    "print(shop_item.info())\n",
    "\n",
    "for col in [\"shop_id\", \"item_id\", \"item_category_id\",\"date_block_num\"]:\n",
    "    shop_item[col] = shop_item[col].astype(\"Int16\")\n",
    "    \n",
    "shop_item.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate sales by month\n",
    "sales_monthly = sales.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg({\n",
    "    \"item_cnt_day\": [\"sum\", \"min\", \"max\"],\n",
    "    \"date\": [\"min\", \"max\", \"count\"],\n",
    "    \"item_price\": [\"mean\", \"max\", \"min\"]\n",
    "}).reset_index()\n",
    "\n",
    "# flatten column names an fill na\n",
    "sales_monthly.columns = [c[0] if c[1] == \"\" else c[1] + \"_\" + c[0] for c in sales_monthly.columns]\n",
    "sales_monthly = sales_monthly.fillna(0) # should only affect std of breakouts of count 1\n",
    "\n",
    "# replace min and max dates by their day of month\n",
    "sales_monthly[\"min_date\"] = sales_monthly.min_date.apply(lambda x: x.day)\n",
    "sales_monthly[\"max_date\"] = sales_monthly.max_date.apply(lambda x: x.day)\n",
    "\n",
    "sales_monthly = sales_monthly.rename({\n",
    "    \"sum_item_cnt_day\": \"item_cnt_month\",\n",
    "}, axis=1)\n",
    "\n",
    "sales_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce memory usage\n",
    "print(sales_monthly.info())\n",
    "\n",
    "for col in [\"item_cnt_month\", \"min_item_cnt_day\", \"max_item_cnt_day\",\n",
    "           \"min_date\", \"max_date\", \"count_date\"]:\n",
    "    sales_monthly[col] = sales_monthly[col].astype(\"Int16\")\n",
    "    \n",
    "sales_monthly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend to all item_id, shop_id combinations and add metadata\n",
    "join_keys = [\"shop_id\", \"item_id\", \"date_block_num\"]\n",
    "sales_monthly = shop_item.join(sales_monthly.set_index(join_keys),\n",
    "                               on=join_keys, how=\"left\")\n",
    "\n",
    "sales_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly.to_pickle(\"data/processed/sales_monthly_full.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly =sales_monthly.sort_values(by=[\"item_id\", \"shop_id\", \"date_block_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly_wide = sales_monthly.set_index([\n",
    "    \"shop_id\",\n",
    "    \"item_id\",\n",
    "    \"item_name\",\n",
    "    \"item_category_id\",\n",
    "    \"item_category_name\",\n",
    "    \"shop_name\",\n",
    "    \"date_block_num\",\n",
    "]).unstack()\n",
    "\n",
    "sales_monthly_wide = sales_monthly_wide.reset_index().fillna(0)\n",
    "\n",
    "sales_monthly_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly_wide.columns = [\n",
    "    c[0] if c[1] == '' else (\n",
    "        c[0] + \"_\" + str(c[1])\n",
    "    ).replace(\"day\", \"month\") for c in sales_monthly_wide.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_monthly_wide.to_pickle(\"data/processed/sales_monthly_wide_full.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-america",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparable-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "sales_monthly_wide = pd.read_pickle(\"data/processed/sales_monthly_wide_full.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "retained-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set_for_month(month, n, X_only=False):\n",
    "    cols = list(sales_monthly_wide.columns)\n",
    "    \n",
    "    train_cols = [\"shop_id\", \"item_id\", \"item_category_id\"]\n",
    "    cols = cols[6:]\n",
    "    train_cols += [c for c in cols if (\n",
    "        int(c.split(\"_\")[-1]) < month and\n",
    "        int(c.split(\"_\")[-1]) > month - n\n",
    "    )]\n",
    "    X = sales_monthly_wide[train_cols]\n",
    "    if not X_only:\n",
    "        y = sales_monthly_wide[[f\"item_cnt_month_{month}\"]]\n",
    "        return X.values, y.values.reshape(-1), train_cols\n",
    "\n",
    "    return X.values, train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ancient-fortune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,   20,   20,   20, -111])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clip(array):\n",
    "    return np.array([min(x, 20) for x in array])\n",
    "\n",
    "clip(np.array([1, 2, 34, 45, 45, -111]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expanded-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546793051465301\n",
      "0.5730118878875057\n",
      "CPU times: user 34min 34s, sys: 41.7 s, total: 35min 16s\n",
      "Wall time: 19min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators = 20,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=100,\n",
    "    n_jobs=-1,  # -1 is all processors used\n",
    ")\n",
    "\n",
    "for i, month in enumerate([33, 32, 31, 30, 29]):\n",
    "    if i == 0:\n",
    "        X, y, cols = get_train_set_for_month(month, 13)\n",
    "        continue\n",
    "    \n",
    "    X_inc, y_inc, _ = get_train_set_for_month(month, 13)\n",
    "    X = np.concatenate((X, X_inc), axis=0)\n",
    "    y = np.concatenate((y, y_inc), axis=0)\n",
    "    \n",
    "    del X_inc, y_inc\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, clip(y_train))\n",
    "\n",
    "print(mean_squared_error(y_true=clip(y_train), y_pred=clip(rf.predict(X_train)), squared=False))\n",
    "print(mean_squared_error(y_true=clip(y_test), y_pred=clip(rf.predict(X_test)), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affiliated-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"mse\", \"mae\"}, default=\"mse\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"mse\" for the mean squared error, which is equal to variance\n",
      " |      reduction as feature selection criterion, and \"mae\" for the mean\n",
      " |      absolute error.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `round(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=None\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 1.0 (renaming of 0.25).\n",
      " |         Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      whether to use out-of-bag samples to estimate\n",
      " |      the R^2 on unseen data.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0, 1)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor, ExtraTreesRegressor\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=\"auto\"`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination :math:`R^2` of the\n",
      " |      prediction.\n",
      " |      \n",
      " |      The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n",
      " |      where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n",
      " |      ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n",
      " |      y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n",
      " |      can be negative (because the model can be arbitrarily worse). A\n",
      " |      constant model that always predicts the expected value of `y`,\n",
      " |      disregarding the input features, would get a :math:`R^2` score of\n",
      " |      0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lonely-aquarium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrf = RandomForestRegressor(\\n    n_estimators = 20,\\n    max_depth=9,\\n    min_samples_leaf=100\\n)\\n\\nfor i, month in enumerate([33, 32, 31, 30]):\\n    if i == 0:\\n        X, y, cols = get_train_set_for_month(month, 13)\\n        continue\\n    \\n    X_inc, y_inc, _ = get_train_set_for_month(month, 13)\\n    X = np.concatenate((X, X_inc), axis=0)\\n    y = np.concatenate((y, y_inc), axis=0)\\n    \\n    del X_inc, y_inc\\n    \\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.33, random_state=42\\n)\\n\\nrf.fit(X_train, clip(y_train))\\n\\n0.5685285035910349\\n0.5749121905190944\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators = 20,\n",
    "    max_depth=9,\n",
    "    min_samples_leaf=100\n",
    ")\n",
    "\n",
    "for i, month in enumerate([33, 32, 31, 30]):\n",
    "    if i == 0:\n",
    "        X, y, cols = get_train_set_for_month(month, 13)\n",
    "        continue\n",
    "    \n",
    "    X_inc, y_inc, _ = get_train_set_for_month(month, 13)\n",
    "    X = np.concatenate((X, X_inc), axis=0)\n",
    "    y = np.concatenate((y, y_inc), axis=0)\n",
    "    \n",
    "    del X_inc, y_inc\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, clip(y_train))\n",
    "\n",
    "0.5685285035910349\n",
    "0.5749121905190944\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cleared-recognition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567.481616"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nbytes / 1000 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "manufactured-revision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('item_cnt_month_32', 0.6970814975510731),\n",
       " ('count_date_32', 0.04899934674008707),\n",
       " ('max_item_price_31', 0.028890211170356533),\n",
       " ('item_cnt_month_31', 0.026693971834871662),\n",
       " ('item_cnt_month_25', 0.024199761948950717),\n",
       " ('max_item_price_32', 0.016116520292818237),\n",
       " ('max_date_32', 0.01381310199974906),\n",
       " ('item_cnt_month_30', 0.013735322436655133),\n",
       " ('item_cnt_month_27', 0.01122911422884782),\n",
       " ('min_date_32', 0.009514050459640022),\n",
       " ('max_item_cnt_month_32', 0.009346789507486781),\n",
       " ('mean_item_price_32', 0.007883511921417521),\n",
       " ('count_date_23', 0.007475998639983135),\n",
       " ('item_category_id', 0.0071488923190803615),\n",
       " ('count_date_25', 0.006799354731528827),\n",
       " ('item_cnt_month_24', 0.006720643569510539),\n",
       " ('item_id', 0.006294735450272981),\n",
       " ('count_date_31', 0.005084288997249555),\n",
       " ('count_date_30', 0.004352664857021647),\n",
       " ('item_cnt_month_26', 0.003969669457451572),\n",
       " ('item_cnt_month_28', 0.003567898143935424),\n",
       " ('count_date_29', 0.003196342163968162),\n",
       " ('mean_item_price_30', 0.002601248372816432),\n",
       " ('max_date_30', 0.0022658322747129223),\n",
       " ('max_item_cnt_month_25', 0.0020281452117189595),\n",
       " ('item_cnt_month_29', 0.001784295377531895),\n",
       " ('min_item_price_32', 0.0016359656190457227),\n",
       " ('min_item_price_30', 0.0016200679664498262),\n",
       " ('count_date_27', 0.0015530696217935613),\n",
       " ('max_item_price_30', 0.0014376678290970017),\n",
       " ('max_item_cnt_month_23', 0.0013371942102639886),\n",
       " ('min_item_price_31', 0.0012956847607957065),\n",
       " ('count_date_26', 0.0011775866603768936),\n",
       " ('max_item_cnt_month_30', 0.001165803128614183),\n",
       " ('shop_id', 0.001124328536269378),\n",
       " ('max_item_price_29', 0.0010070167753394243),\n",
       " ('mean_item_price_31', 0.0010052546953625082),\n",
       " ('count_date_28', 0.000982563043611224),\n",
       " ('max_date_25', 0.0008740947108842864),\n",
       " ('min_item_price_29', 0.0007351635034061777),\n",
       " ('max_date_31', 0.0006997931167829568),\n",
       " ('max_date_29', 0.0006347067884247067),\n",
       " ('min_date_31', 0.0005800861014922806),\n",
       " ('max_date_21', 0.0005730999651274168),\n",
       " ('mean_item_price_29', 0.0005433534434857959),\n",
       " ('max_item_cnt_month_31', 0.0005338641285183419),\n",
       " ('min_item_price_28', 0.0004789244145315754),\n",
       " ('max_date_28', 0.00045862413631744483),\n",
       " ('item_cnt_month_22', 0.0004007568820228487),\n",
       " ('count_date_24', 0.0003771363818469752),\n",
       " ('max_item_cnt_month_21', 0.0003603663743814746),\n",
       " ('item_cnt_month_23', 0.0003583302384073619),\n",
       " ('min_date_30', 0.0003514924231269772),\n",
       " ('max_date_27', 0.0003408082152104836),\n",
       " ('max_item_price_28', 0.00031874700100242907),\n",
       " ('mean_item_price_28', 0.00031119041439851836),\n",
       " ('max_date_26', 0.00030938887910697793),\n",
       " ('max_item_price_27', 0.0003091011929620286),\n",
       " ('max_item_cnt_month_29', 0.0002972460234624061),\n",
       " ('max_date_24', 0.00024930407583215614),\n",
       " ('min_date_29', 0.00021003656076032506),\n",
       " ('min_item_price_27', 0.00019176723041502243),\n",
       " ('max_date_23', 0.0001869035734999731),\n",
       " ('min_date_25', 0.00017589616903537227),\n",
       " ('max_date_22', 0.00017324942254140323),\n",
       " ('max_item_price_26', 0.0001642769861689555),\n",
       " ('mean_item_price_25', 0.00015648210109332),\n",
       " ('min_date_27', 0.00014676199337121902),\n",
       " ('min_date_26', 0.00014196527568512612),\n",
       " ('max_item_price_25', 0.00013411913841084275),\n",
       " ('max_item_cnt_month_24', 0.0001336693961929402),\n",
       " ('mean_item_price_23', 0.00013322695482251057),\n",
       " ('mean_item_price_26', 0.00013252535774085306),\n",
       " ('max_item_price_22', 0.00011934933333622658),\n",
       " ('min_date_24', 0.0001076169822881136),\n",
       " ('count_date_22', 0.00010712676575409255),\n",
       " ('mean_item_price_27', 0.00010499390470641039),\n",
       " ('max_item_cnt_month_26', 9.976956149143887e-05),\n",
       " ('min_item_price_25', 9.32965262562144e-05),\n",
       " ('min_item_price_24', 9.100311645223784e-05),\n",
       " ('min_date_28', 7.876775450915787e-05),\n",
       " ('item_cnt_month_21', 7.483671758503473e-05),\n",
       " ('max_item_cnt_month_27', 7.45170389902102e-05),\n",
       " ('mean_item_price_22', 7.314698388614886e-05),\n",
       " ('count_date_21', 7.167422952301044e-05),\n",
       " ('max_item_cnt_month_28', 6.67788896272556e-05),\n",
       " ('min_item_price_26', 6.666213280137018e-05),\n",
       " ('mean_item_price_24', 5.654238737862599e-05),\n",
       " ('min_date_22', 5.3595007699856395e-05),\n",
       " ('min_date_23', 4.944144726224e-05),\n",
       " ('min_item_price_22', 4.279271872767171e-05),\n",
       " ('max_item_price_21', 3.399678681187688e-05),\n",
       " ('min_item_cnt_month_30', 2.8744902740331396e-05),\n",
       " ('min_date_21', 2.790837728287066e-05),\n",
       " ('min_item_cnt_month_29', 2.700847228579908e-05),\n",
       " ('min_item_price_23', 2.593505070414249e-05),\n",
       " ('min_item_price_21', 2.493861725651529e-05),\n",
       " ('mean_item_price_21', 1.9366680883887494e-05),\n",
       " ('max_item_price_24', 1.809542258834152e-05),\n",
       " ('max_item_price_23', 1.4289796723901596e-05),\n",
       " ('min_item_cnt_month_25', 8.872126472648337e-06),\n",
       " ('min_item_cnt_month_27', 7.977414810195863e-06),\n",
       " ('min_item_cnt_month_28', 7.0587176695507056e-06),\n",
       " ('min_item_cnt_month_24', 5.676261332392708e-06),\n",
       " ('min_item_cnt_month_32', 4.203406562301201e-06),\n",
       " ('max_item_cnt_month_22', 1.1356808577511498e-06),\n",
       " ('min_item_cnt_month_23', 1.0097105171424074e-06),\n",
       " ('min_item_cnt_month_21', 0.0),\n",
       " ('min_item_cnt_month_22', 0.0),\n",
       " ('min_item_cnt_month_26', 0.0),\n",
       " ('min_item_cnt_month_31', 0.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = list(zip(cols, rf.feature_importances_))\n",
    "\n",
    "feature_imp.sort(key= lambda x: x[1], reverse=True)\n",
    "\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinguished-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for Nov!\n",
    "\n",
    "X, cols = get_train_set_for_month(34, 13, X_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coordinate-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 30, 40, ..., 0.0, 0.0, 0.0],\n",
       "       [0, 31, 37, ..., 0.0, 0.0, 0.0],\n",
       "       [0, 32, 40, ..., 0.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       [59, 22164, 37, ..., 0.0, 0.0, 0.0],\n",
       "       [59, 22166, 54, ..., 0.0, 0.0, 0.0],\n",
       "       [59, 22167, 49, ..., 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "matched-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ranging-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02934008, 0.02934008, 0.02934008, ..., 0.1719791 , 0.02993272,\n",
       "       0.02993272])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incorrect-thinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526915</th>\n",
       "      <td>59</td>\n",
       "      <td>22162</td>\n",
       "      <td>0.261748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526916</th>\n",
       "      <td>59</td>\n",
       "      <td>22163</td>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526917</th>\n",
       "      <td>59</td>\n",
       "      <td>22164</td>\n",
       "      <td>0.171979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526918</th>\n",
       "      <td>59</td>\n",
       "      <td>22166</td>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526919</th>\n",
       "      <td>59</td>\n",
       "      <td>22167</td>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       shop_id item_id  item_cnt_month\n",
       "0            0      30        0.029340\n",
       "1            0      31        0.029340\n",
       "2            0      32        0.029340\n",
       "3            0      33        0.029340\n",
       "4            0      35        0.029340\n",
       "...        ...     ...             ...\n",
       "526915      59   22162        0.261748\n",
       "526916      59   22163        0.029933\n",
       "526917      59   22164        0.171979\n",
       "526918      59   22166        0.029933\n",
       "526919      59   22167        0.029933\n",
       "\n",
       "[526920 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X, columns=cols)[[\"shop_id\", \"item_id\"]]\n",
    "X[\"item_cnt_month\"] = clip(y_pred)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "strange-oxide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>526920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.110043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.430638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.033297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.643013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_cnt_month\n",
       "count   526920.000000\n",
       "mean         0.110043\n",
       "std          0.430638\n",
       "min          0.029340\n",
       "25%          0.029933\n",
       "50%          0.029933\n",
       "75%          0.033297\n",
       "max         17.643013"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "popular-cargo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.641952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.081769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.112062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.292670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214195</th>\n",
       "      <td>214195</td>\n",
       "      <td>0.293442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214196</th>\n",
       "      <td>214196</td>\n",
       "      <td>0.031264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214197</th>\n",
       "      <td>214197</td>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214198</th>\n",
       "      <td>214198</td>\n",
       "      <td>0.029933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214199</th>\n",
       "      <td>214199</td>\n",
       "      <td>0.029340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  item_cnt_month\n",
       "0            0        0.641952\n",
       "1            1        0.029340\n",
       "2            2        1.081769\n",
       "3            3        0.112062\n",
       "4            4        0.292670\n",
       "...        ...             ...\n",
       "214195  214195        0.293442\n",
       "214196  214196        0.031264\n",
       "214197  214197        0.029933\n",
       "214198  214198        0.029933\n",
       "214199  214199        0.029340\n",
       "\n",
       "[214200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"data/source/test.csv\")\n",
    "\n",
    "submission = submission.join(\n",
    "    X.set_index([\"shop_id\", \"item_id\"]), on=[\"shop_id\", \"item_id\"], how=\"left\"\n",
    ")[[\"ID\", \"item_cnt_month\"]]\n",
    "\n",
    "display(submission)\n",
    "\n",
    "submission.to_csv(\"data/submission_full_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "apparent-study",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TODO's:\\n\\n- Feature enginnering on names of shops, items, item_cats\\n- features for price delta\\n- features on overall shop and item performance\\n- add model pickle section\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"TODO's:\n",
    "\n",
    "- Feature enginnering on names of shops, items, item_cats\n",
    "- features for price delta\n",
    "- features on overall shop and item performance\n",
    "- add model pickle section\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
